README for OHLT rate scripts

Contacts : cms-tsg-steam-rates@cern.ch
  
************************************** 
1. Introduction
************************************** 



--------------------------------------  
1a. Running the scripts
--------------------------------------  
 
  Once the binary file is built, the rate-calculating script can be run using:
  
  ./OHltRateEff <cfgfile> 

  Some arguments in the cfg file are as follows (see example hltmenu_1E31_2008Dec04.cfg):
  [incomplete docu here!]
    
    nEntries: Number of events to run over.
          That number will be used for each sample.
          If there exist less events in a sample than requested than the script
          will run over all existing.
          Any number < 0 will be interpreted as "running over all existing events".
          Default is all (-1).
  
    versionTag: A string describing this menu. This will be appended to the name of the output files.
          
    doPrintAll: If set to 1 all printouts incl. overlap coefficient etc,
            and also the TeX file is generated.
            Otherwise only the most basic  info is printed out to stdout.
    
    

**************************************
2. Input samples and cross-sections
**************************************
  Samples are registered via the process tag, example:

	process:{
 		names = ["minbias","qcdpt30"]; # arbitrary names
 		paths = ["/uscmst1b_scratch/lpc1/lpctrig/apana/data/MinBias/lumi8e29/",
			"/uscmst1b_scratch/lpc1/lpctrig/apana/data/QCDpt30/lumi8e29/];
			# paths to set of files
 		fnames = ["Summer08_MinBias*root","Summer08_QCDpt30*root"];
			# list of filenames, asterisks can be used
 		doMuonCuts = [false];
			# against muon double counting, only used for special case
			# if enriched muon samples are used with minbias samples, otherwise always 'false'
 		doElecCuts = [false]; #
			# against electron double counting, only used for special case
			# if enriched electron samples are used with minbias, otherwise always 'false'
 		sigmas = [7.53E10,1E8]; # 10 TeV xsecs * filter efficiencies
	};


--------------------------------------
3. Primary Datasets code
--------------------------------------

  The primary datasets evaluation happens as part of the event loop. Its purpose is to
    1) Evaluate the rates of datasets, correlation (i.e. fraction of shared events) between 
       datasets, and total output overhead for storing datasets. 
    2) Evaluate the correlation of "new triggers" with the primary datasets, and also the
       rate of unique events that can be added by a particular new trigger to each of the
       primary datasets, if it were to be placed in that location.
       
  The "new triggers" are defined to be all the triggers that do not appear in one or more
  primary datasets, as read from the <sPrimaryDatasets> input file. As mentioned, if
  <sPrimaryDatasets> = "" is provided, every trigger is considered to be a dataset (so, 
  there are _no_ new triggers) -- this is useful for outputting the trigger-vs-trigger
  correlation plot, which can help you diagnose whether your proposed trigger has already
  been (mostly) superceded by some other trigger(s).
  
  The code produces two output files:
    a) X_scenario_correlations.root : a few histograms (one per sample, and for "all", "rate",
                                      and "physics" combinations of samples) with the 2D 
                                      correlation plots that can be used for deciding which 
                                      triggers go into which datasets.
    b) X_scenario_correlations.pdf  : essentially the same information as (a), but in numerical 
                                      form (tables). Specifically, this shows the rate that 
                                      would be added by each trigger, if it were to be added to 
                                      a particular dataset.
  Here X is the same as the OHltRateEff main output name.
  
